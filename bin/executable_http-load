#!/bin/bash

# Download a whole website

# Check if URL is provided
if [ -z "$1" ]; then
    echo "Usage: $0 <website_url>"
    exit 1
fi

# Define the website URL
WEBSITE_URL=$1

# Download the website and log details
wget \
  --mirror `#shortcut for -N -r -l inf --no-remove-listing` \
  --continue `#resume getting a partially-downloaded file` \
  --level=inf \
  --no-parent \
  --quiet \
  --progress=TYPE `#select progress gauge type` \
  --show-progress `#display the progress bar in any verbosity mode` \
  --timeout=2 `#set all timeout values to SECONDS` \
  --waitretry=3 `#wait SECONDS between retries of a retrieval` \
  --output-file=wget-output.txt \
  --append-output=wget-append.txt \
  --output-document=wget-document.txt
  "$WEBSITE_URL"

# Count the number of requests made (lines starting with "HTTP" in the log)
TOTAL_REQUESTS=$(grep -c "HTTP/" wget-log.txt)

# Output the number of requests made
echo "Total requests made to download the website: $TOTAL_REQUESTS"

# Clean up the log file if necessary
# rm wget-log.txt