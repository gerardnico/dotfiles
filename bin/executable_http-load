#!/bin/bash

# Download a whole website

# Check if URL is provided
if [ -z "$1" ]; then
    echo "Usage: $0 <website_url>"
    exit 1
fi

# Define the website URL
WEBSITE_URL=$1

# Download the website and log details
wget \
  --mirror \
  --continue \
  --level=inf \
  --no-parent \
  --quiet \
  --progress=bar:force  \
  --show-progress \
  --timeout=2 \
  --waitretry=3 \
  --output-file=wget-output.txt \
  --append-output=wget-append.txt \
  "$WEBSITE_URL"
# where
# quiet    - turn of wget output
# mirror   - shortcut for -N -r -l inf --no-remove-listing
# continue - resume getting a partially-downloaded file
# show-progress - display the progress bar in any verbosity mode
# progress=type - select the progress bar type
# timeout   - set all timeout values to SECONDS
# waitretry - wait SECONDS between retries of a retrieval
# output-document - will save the document (ie body response)


# Count the number of requests made (lines starting with "HTTP" in the log)
TOTAL_REQUESTS=$(grep -c "HTTP/" wget-log.txt)

# Output the number of requests made
echo "Total requests made to download the website: $TOTAL_REQUESTS"

# Clean up the log file if necessary
# rm wget-log.txt